{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424c3eb6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-07T20:45:07.592889Z",
     "iopub.status.busy": "2024-11-07T20:45:07.592487Z",
     "iopub.status.idle": "2024-11-07T20:45:08.566930Z",
     "shell.execute_reply": "2024-11-07T20:45:08.565875Z"
    },
    "papermill": {
     "duration": 0.981497,
     "end_time": "2024-11-07T20:45:08.569410",
     "exception": false,
     "start_time": "2024-11-07T20:45:07.587913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dataaa/A21P12/rgb/651_A21P12_.avi\n",
      "/kaggle/input/dataaa/A21P12/rgb/893_A21P12_.avi\n",
      "/kaggle/input/dataaa/A21P12/rgb/1326_A21P12_.avi\n",
      "/kaggle/input/dataaa/A21P12/rgb/1077_A21P12_.avi\n",
      "/kaggle/input/dataaa/A21P12/rgb/819_A21P12_.avi\n",
      "/kaggle/input/dataaa/A21P12/rgb/1163_A21P12_.avi\n",
      "/kaggle/input/dataaa/A21P12/rgb/996_A21P12_.avi\n",
      "/kaggle/input/dataaa/A21P12/rgb/737_A21P12_.avi\n",
      "/kaggle/input/dataaa/A21P12/rgb/1243_A21P12_.avi\n",
      "/kaggle/input/dataaa/A21P14/rgb/742_A21P14_.avi\n",
      "/kaggle/input/dataaa/A21P14/rgb/856_A21P14_.avi\n",
      "/kaggle/input/dataaa/A21P14/rgb/1064_A21P14_.avi\n",
      "/kaggle/input/dataaa/A21P14/rgb/401_A21P14_.avi\n",
      "/kaggle/input/dataaa/A21P14/rgb/963_A21P14_.avi\n",
      "/kaggle/input/dataaa/A21P14/rgb/294_A21P14_.avi\n",
      "/kaggle/input/dataaa/A21P14/rgb/510_A21P14_.avi\n",
      "/kaggle/input/dataaa/A21P14/rgb/627_A21P14_.avi\n",
      "/kaggle/input/dataaa/A21P14/rgb/192_A21P14_.avi\n",
      "/kaggle/input/dataaa/A21P11/rgb/646_A21P11_.avi\n",
      "/kaggle/input/dataaa/A21P11/rgb/1043_A21P11_.avi\n",
      "/kaggle/input/dataaa/A21P11/rgb/532_A21P11_.avi\n",
      "/kaggle/input/dataaa/A21P11/rgb/831_A21P11_.avi\n",
      "/kaggle/input/dataaa/A21P11/rgb/732_A21P11_.avi\n",
      "/kaggle/input/dataaa/A21P11/rgb/1230_A21P11_.avi\n",
      "/kaggle/input/dataaa/A21P11/rgb/1143_A21P11_.avi\n",
      "/kaggle/input/dataaa/A21P11/rgb/441_A21P11_.avi\n",
      "/kaggle/input/dataaa/A21P11/rgb/936_A21P11_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/1099_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/755_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/856_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/974_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/1232_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/635_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/144_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/389_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/511_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P13/rgb/261_A21P13_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/564_A21P15_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/1461_A21P15_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/1712_A21P15_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/677_A21P15_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/1083_A21P15_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/1219_A21P15_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/806_A21P15_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/944_A21P15_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/1329_A21P15_.avi\n",
      "/kaggle/input/dataaa/A21P15/rgb/1588_A21P15_.avi\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae993435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:45:08.576846Z",
     "iopub.status.busy": "2024-11-07T20:45:08.576076Z",
     "iopub.status.idle": "2024-11-07T20:45:10.350132Z",
     "shell.execute_reply": "2024-11-07T20:45:10.349045Z"
    },
    "papermill": {
     "duration": 1.780114,
     "end_time": "2024-11-07T20:45:10.352562",
     "exception": false,
     "start_time": "2024-11-07T20:45:08.572448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'FeaturesFusionRGBDepth'...\r\n",
      "remote: Enumerating objects: 463, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (14/14), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\r\n",
      "remote: Total 463 (delta 5), reused 7 (delta 3), pack-reused 449 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (463/463), 129.49 KiB | 1.66 MiB/s, done.\r\n",
      "Resolving deltas: 100% (280/280), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MebNa/FeaturesFusionRGBDepth.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cde3e88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:45:10.360683Z",
     "iopub.status.busy": "2024-11-07T20:45:10.360330Z",
     "iopub.status.idle": "2024-11-07T20:45:43.407360Z",
     "shell.execute_reply": "2024-11-07T20:45:43.406119Z"
    },
    "papermill": {
     "duration": 33.053848,
     "end_time": "2024-11-07T20:45:43.409772",
     "exception": false,
     "start_time": "2024-11-07T20:45:10.355924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/FeaturesFusionRGBDepth\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.4.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.19.0)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (4.10.0.84)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.26.4)\r\n",
      "Collecting mediapipe (from -r requirements.txt (line 5))\r\n",
      "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.15.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->-r requirements.txt (line 2)) (10.3.0)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from mediapipe->-r requirements.txt (line 5)) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe->-r requirements.txt (line 5)) (23.2.0)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from mediapipe->-r requirements.txt (line 5)) (24.3.25)\r\n",
      "Requirement already satisfied: jax in /opt/conda/lib/python3.10/site-packages (from mediapipe->-r requirements.txt (line 5)) (0.4.26)\r\n",
      "Requirement already satisfied: jaxlib in /opt/conda/lib/python3.10/site-packages (from mediapipe->-r requirements.txt (line 5)) (0.4.26.dev20240620)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from mediapipe->-r requirements.txt (line 5)) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/conda/lib/python3.10/site-packages (from mediapipe->-r requirements.txt (line 5)) (4.10.0.84)\r\n",
      "Collecting protobuf<5,>=4.25.3 (from mediapipe->-r requirements.txt (line 5))\r\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\r\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe->-r requirements.txt (line 5))\r\n",
      "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from mediapipe->-r requirements.txt (line 5)) (0.2.0)\r\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/conda/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe->-r requirements.txt (line 5)) (1.16.0)\r\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe->-r requirements.txt (line 5)) (0.3.2)\r\n",
      "Requirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe->-r requirements.txt (line 5)) (3.3.0)\r\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax->mediapipe->-r requirements.txt (line 5)) (1.14.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.5)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe->-r requirements.txt (line 5)) (1.2.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe->-r requirements.txt (line 5)) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe->-r requirements.txt (line 5)) (4.53.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe->-r requirements.txt (line 5)) (1.4.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe->-r requirements.txt (line 5)) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe->-r requirements.txt (line 5)) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->mediapipe->-r requirements.txt (line 5)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe->-r requirements.txt (line 5)) (2.22)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe->-r requirements.txt (line 5)) (1.16.0)\r\n",
      "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\r\n",
      "Installing collected packages: protobuf, sounddevice, mediapipe\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.5 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\r\n",
      "google-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\r\n",
      "google-cloud-bigquery 2.34.4 requires protobuf<4.0.0dev,>=3.12.0, but you have protobuf 4.25.5 which is incompatible.\r\n",
      "google-cloud-bigtable 1.7.3 requires protobuf<4.0.0dev, but you have protobuf 4.25.5 which is incompatible.\r\n",
      "google-cloud-vision 2.8.0 requires protobuf<4.0.0dev,>=3.19.0, but you have protobuf 4.25.5 which is incompatible.\r\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\r\n",
      "kfp 2.5.0 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\r\n",
      "kfp-pipeline-spec 0.2.2 requires protobuf<4,>=3.13.0, but you have protobuf 4.25.5 which is incompatible.\r\n",
      "tensorflow-metadata 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\r\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed mediapipe-0.10.18 protobuf-4.25.3 sounddevice-0.5.1\r\n",
      "Obtaining file:///kaggle/working/FeaturesFusionRGBDepth\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\r\n",
      "\u001b[?25hInstalling collected packages: my_project\r\n",
      "  Running setup.py develop for my_project\r\n",
      "Successfully installed my_project-0.1\r\n"
     ]
    }
   ],
   "source": [
    "%cd FeaturesFusionRGBDepth\n",
    "!pip install -r requirements.txt\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "658594f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:45:43.424616Z",
     "iopub.status.busy": "2024-11-07T20:45:43.423555Z",
     "iopub.status.idle": "2024-11-07T20:46:10.142525Z",
     "shell.execute_reply": "2024-11-07T20:46:10.141471Z"
    },
    "papermill": {
     "duration": 26.729106,
     "end_time": "2024-11-07T20:46:10.145105",
     "exception": false,
     "start_time": "2024-11-07T20:45:43.415999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate frequently: 100\r\n",
      "Num gradient per update: 25\r\n",
      "Gathering dataset information from 5 batches...\r\n",
      "\r\n",
      "5it [00:00, 130.78it/s]\r\n",
      "Loaded 1 classes ['ke_sach']\r\n",
      "Loaded 5 persons ['12', '14', '11', '13', '15']\r\n",
      "Train: 3  Val: 1  Test: 1\r\n",
      "Train set size: 28\r\n",
      "Validation set size: 10\r\n",
      "Test set size: 9\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\r\n",
      "  warnings.warn(_create_warning_msg(\r\n",
      "Downloading: \"https://download.pytorch.org/models/s3d-d76dad2f.pth\" to /root/.cache/torch/hub/checkpoints/s3d-d76dad2f.pth\r\n",
      "100%|██████████████████████████████████████| 32.0M/32.0M [00:00<00:00, 67.8MB/s]\r\n",
      "Train on cuda:1\r\n",
      "Model name s3d \r\n",
      " 78%|███████████████████████████████████          | 7/9 [00:11<00:03,  1.71s/it]\r\n",
      "Evaluating:   0%|                                         | 0/3 [00:01<?, ?it/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\r\n",
      "  avg = a.mean(axis, **keepdims_kw)\r\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\r\n",
      "  ret = ret.dtype.type(ret / rcount)\r\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py:148: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\r\n",
      "  self.im_ = ax.imshow(cm, **im_kw)\r\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py:148: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\r\n",
      "  self.im_ = ax.imshow(cm, **im_kw)\r\n",
      "2024-11-07 20:46:08,298 [MainThread  ] [ERROR]  Uncaught exception\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 333, in <module>\r\n",
      "    run(\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 256, in run\r\n",
      "    current_valid_loss = evaluate(model,model_name,dataloaders['val'],loss_fn,steps,class_info,ep = epoch,device=device)\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 73, in evaluate\r\n",
      "    elog.save_confusion_matrix(\"valid\",ep, logits,class_info)\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/eval.py\", line 68, in save_confusion_matrix\r\n",
      "    display.plot(ax=ax,cmap='Blues', values_format='.2f' if normalize else 'd')\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py\", line 156, in plot\r\n",
      "    thresh = (cm.max() + cm.min()) / 2.0\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py\", line 41, in _amax\r\n",
      "    return umr_maximum(a, axis, None, out, keepdims, initial, where)\r\n",
      "ValueError: zero-size array to reduction operation maximum which has no identity\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 333, in <module>\r\n",
      "    run(\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 256, in run\r\n",
      "    current_valid_loss = evaluate(model,model_name,dataloaders['val'],loss_fn,steps,class_info,ep = epoch,device=device)\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 73, in evaluate\r\n",
      "    elog.save_confusion_matrix(\"valid\",ep, logits,class_info)\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/eval.py\", line 68, in save_confusion_matrix\r\n",
      "    display.plot(ax=ax,cmap='Blues', values_format='.2f' if normalize else 'd')\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py\", line 156, in plot\r\n",
      "    thresh = (cm.max() + cm.min()) / 2.0\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py\", line 41, in _amax\r\n",
      "    return umr_maximum(a, axis, None, out, keepdims, initial, where)\r\n",
      "ValueError: zero-size array to reduction operation maximum which has no identity\r\n"
     ]
    }
   ],
   "source": [
    "!python train_sh/train.py --device='cuda:1' --root=\"/kaggle/input/dataaa\" --batch_size=3 --model_name='s3d' --evaluate_frequently=100 --epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e331e0e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-07T20:46:10.163577Z",
     "iopub.status.busy": "2024-11-07T20:46:10.163160Z",
     "iopub.status.idle": "2024-11-07T20:46:30.690244Z",
     "shell.execute_reply": "2024-11-07T20:46:30.689221Z"
    },
    "papermill": {
     "duration": 20.539407,
     "end_time": "2024-11-07T20:46:30.692731",
     "exception": false,
     "start_time": "2024-11-07T20:46:10.153324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate frequently: 100\r\n",
      "Num gradient per update: 25\r\n",
      "Gathering dataset information from 5 batches...\r\n",
      "\r\n",
      "5it [00:00, 184.95it/s]\r\n",
      "Loaded 1 classes ['ke_sach']\r\n",
      "Loaded 5 persons ['12', '14', '11', '13', '15']\r\n",
      "Train: 3  Val: 1  Test: 1\r\n",
      "Train set size: 28\r\n",
      "Validation set size: 10\r\n",
      "Test set size: 9\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\r\n",
      "  warnings.warn(_create_warning_msg(\r\n",
      "Train on cuda:1\r\n",
      "Model name s3d \r\n",
      " 78%|███████████████████████████████████          | 7/9 [00:11<00:03,  1.61s/it]\r\n",
      "Evaluating:   0%|                                         | 0/3 [00:01<?, ?it/s]\r\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\r\n",
      "  avg = a.mean(axis, **keepdims_kw)\r\n",
      "/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\r\n",
      "  ret = ret.dtype.type(ret / rcount)\r\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py:148: UserWarning: Attempting to set identical low and high xlims makes transformation singular; automatically expanding.\r\n",
      "  self.im_ = ax.imshow(cm, **im_kw)\r\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py:148: UserWarning: Attempting to set identical low and high ylims makes transformation singular; automatically expanding.\r\n",
      "  self.im_ = ax.imshow(cm, **im_kw)\r\n",
      "2024-11-07 20:46:29,434 [MainThread  ] [ERROR]  Uncaught exception\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 333, in <module>\r\n",
      "    run(\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 256, in run\r\n",
      "    current_valid_loss = evaluate(model,model_name,dataloaders['val'],loss_fn,steps,class_info,ep = epoch,device=device)\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 73, in evaluate\r\n",
      "    elog.save_confusion_matrix(\"valid\",ep, logits,class_info)\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/eval.py\", line 68, in save_confusion_matrix\r\n",
      "    display.plot(ax=ax,cmap='Blues', values_format='.2f' if normalize else 'd')\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py\", line 156, in plot\r\n",
      "    thresh = (cm.max() + cm.min()) / 2.0\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py\", line 41, in _amax\r\n",
      "    return umr_maximum(a, axis, None, out, keepdims, initial, where)\r\n",
      "ValueError: zero-size array to reduction operation maximum which has no identity\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 333, in <module>\r\n",
      "    run(\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 256, in run\r\n",
      "    current_valid_loss = evaluate(model,model_name,dataloaders['val'],loss_fn,steps,class_info,ep = epoch,device=device)\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/train.py\", line 73, in evaluate\r\n",
      "    elog.save_confusion_matrix(\"valid\",ep, logits,class_info)\r\n",
      "  File \"/kaggle/working/FeaturesFusionRGBDepth/train_sh/eval.py\", line 68, in save_confusion_matrix\r\n",
      "    display.plot(ax=ax,cmap='Blues', values_format='.2f' if normalize else 'd')\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_plot/confusion_matrix.py\", line 156, in plot\r\n",
      "    thresh = (cm.max() + cm.min()) / 2.0\r\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py\", line 41, in _amax\r\n",
      "    return umr_maximum(a, axis, None, out, keepdims, initial, where)\r\n",
      "ValueError: zero-size array to reduction operation maximum which has no identity\r\n"
     ]
    }
   ],
   "source": [
    "!python train_sh/train.py --device='cuda:1' --root=\"/kaggle/input/dataaa\" --batch_size=3 --model_name='s3d' --evaluate_frequently=100 --epochs=20"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6025176,
     "sourceId": 9825313,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 86.673472,
   "end_time": "2024-11-07T20:46:31.021519",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-07T20:45:04.348047",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
